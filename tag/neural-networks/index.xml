<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>neural networks | leminhnguyen&#39;s blog</title>
    <link>https://leminhnguyen.github.io/tag/neural-networks/</link>
      <atom:link href="https://leminhnguyen.github.io/tag/neural-networks/index.xml" rel="self" type="application/rss+xml" />
    <description>neural networks</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><copyright>¬© {2025} leminhnguyen</copyright><lastBuildDate>Fri, 04 Apr 2025 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://leminhnguyen.github.io/media/icon_hua2ec155b4296a9c9791d015323e16eb5_11927_512x512_fill_lanczos_center_3.png</url>
      <title>neural networks</title>
      <link>https://leminhnguyen.github.io/tag/neural-networks/</link>
    </image>
    
    <item>
      <title>Why Entropy Matters in Machine Learning?</title>
      <link>https://leminhnguyen.github.io/post/machine-learning/entropy/</link>
      <pubDate>Fri, 04 Apr 2025 00:00:00 +0000</pubDate>
      <guid>https://leminhnguyen.github.io/post/machine-learning/entropy/</guid>
      <description>&lt;div style=&#34;text-align: justify; font-size: 15px; margin-top: 20px margin-bottom: 10px&#34;&gt;














&lt;figure  id=&#34;figure-low-vs-high-entropy&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Low vs High Entropy&#34; srcset=&#34;
               /post/machine-learning/entropy/entropy_in_data_hu774da9d84015d9efdfc2798c918ad7df_132158_6bcaeffca1501bd96ec2cbe2bdf01b35.png 400w,
               /post/machine-learning/entropy/entropy_in_data_hu774da9d84015d9efdfc2798c918ad7df_132158_a693682445ad969ba8be8a82e9a88e93.png 760w,
               /post/machine-learning/entropy/entropy_in_data_hu774da9d84015d9efdfc2798c918ad7df_132158_1200x1200_fit_lanczos_3.png 1200w&#34;
               src=&#34;https://leminhnguyen.github.io/post/machine-learning/entropy/entropy_in_data_hu774da9d84015d9efdfc2798c918ad7df_132158_6bcaeffca1501bd96ec2cbe2bdf01b35.png&#34;
               width=&#34;700&#34;
               height=&#34;256&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Low vs High Entropy
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;&lt;strong&gt;Entropy&lt;/strong&gt; is a powerful and fundamental concept that quietly drives some of the most effective algorithms in machine learning. From decision trees to deep neural networks, entropy plays a central role in helping models navigate uncertainty and make better predictions.&lt;/p&gt;
&lt;h3 id=&#34;what-is-entropy&#34;&gt;What Is Entropy?&lt;/h3&gt;
&lt;p&gt;Originally a concept from thermodynamics, entropy measures the level of &lt;strong&gt;disorder&lt;/strong&gt; or &lt;strong&gt;uncertainty&lt;/strong&gt; in a system. In machine learning, it&amp;rsquo;s used to quantify how much unpredictability exists in a set of outcomes.&lt;/p&gt;
&lt;p&gt;Take a coin flip, for example:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;If you flip a fair coin and get &lt;code&gt;[heads, tails, tails, heads]&lt;/code&gt;, there&amp;rsquo;s high entropy ‚Äî the outcomes are unpredictable.&lt;/li&gt;
&lt;li&gt;But if you flip a weighted coin and get &lt;code&gt;[tails, tails, tails, tails]&lt;/code&gt;, entropy is low ‚Äî the system is more predictable.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In general:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;High entropy&lt;/strong&gt; = low information gain (we learn less from each new example).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Low entropy&lt;/strong&gt; = high information gain (we learn more from each new example).&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;entropy-in-decision-trees&#34;&gt;Entropy in Decision Trees&lt;/h3&gt;
&lt;p&gt;Entropy is the secret sauce behind decision trees. When a decision tree decides where to split the data, it doesn&amp;rsquo;t just guess‚Äîit asks:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;‚ÄúWhich feature split gives me the most certainty about what‚Äôs going on?‚Äù&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;It measures the entropy of each feature. The split that &lt;strong&gt;reduces entropy the most&lt;/strong&gt; (i.e., gives the most information gain) gets picked. It‚Äôs like asking:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;‚ÄúWhich question brings me closer to the truth?‚Äù&lt;/p&gt;
&lt;/blockquote&gt;














&lt;figure  id=&#34;figure-decision-tree-example-source-andre-ye&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Decision Tree Example (source: Andre Ye)&#34; srcset=&#34;
               /post/machine-learning/entropy/decision_tree_hu2fc7734e24d263dd4c849451e1112706_65155_d8e79941847cb4700b891eda18c2fdd0.png 400w,
               /post/machine-learning/entropy/decision_tree_hu2fc7734e24d263dd4c849451e1112706_65155_a3f99da1f104f0db8ae4fb4e95b76141.png 760w,
               /post/machine-learning/entropy/decision_tree_hu2fc7734e24d263dd4c849451e1112706_65155_1200x1200_fit_lanczos_3.png 1200w&#34;
               src=&#34;https://leminhnguyen.github.io/post/machine-learning/entropy/decision_tree_hu2fc7734e24d263dd4c849451e1112706_65155_d8e79941847cb4700b891eda18c2fdd0.png&#34;
               width=&#34;700&#34;
               height=&#34;335&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Decision Tree Example (source: Andre Ye)
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;For instance, if you&amp;rsquo;re building a tree to classify colors into red or blue, and one feature creates two groups that are nearly all red and all blue‚Äîthat‚Äôs &lt;strong&gt;low entropy&lt;/strong&gt;, and that feature becomes a &lt;strong&gt;high-value decision&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;This is why trees often start with the most informative feature at the top: to guide the rest of the tree with clarity and purpose.&lt;/p&gt;
&lt;h3 id=&#34;cross-entropy-in-neural-networks&#34;&gt;Cross-Entropy in Neural Networks&lt;/h3&gt;
&lt;p&gt;In deep learning, entropy shows up again‚Äîthis time in disguise, as &lt;strong&gt;cross-entropy&lt;/strong&gt;, a favorite loss function of neural networks. Imagine you&amp;rsquo;re training a model to classify images of cats and dogs. Cross-entropy doesn&amp;rsquo;t just care &lt;em&gt;which&lt;/em&gt; label the model picked‚Äîit cares &lt;em&gt;how confident&lt;/em&gt; the model was.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;If your model says ‚ÄúI‚Äôm 99% sure this is a cat‚Äù and it‚Äôs correct: great.&lt;/li&gt;
&lt;li&gt;If it says ‚Äú50-50, could be cat or dog‚Äù ‚Äî not so great.&lt;/li&gt;
&lt;li&gt;If it‚Äôs confidently wrong ‚Äî disaster.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Cross-entropy punishes bad guesses and rewards confident, correct predictions. It pushes the model to not just be right, but to be sure of why it&amp;rsquo;s right. Cross-entropy measures how many bits are needed to encode the true labels using the predicted distribution. The lower the value, the better the model&amp;rsquo;s predictions match the truth.&lt;/p&gt;
&lt;p&gt;This works beautifully with &lt;strong&gt;Softmax&lt;/strong&gt; and &lt;strong&gt;Sigmoid&lt;/strong&gt; activations, helping reduce issues like the vanishing gradient problem and giving models a smoother learning curve. This approach is:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;More dynamic than accuracy/error-based metrics.&lt;/li&gt;
&lt;li&gt;Better at handling confidence and probability.&lt;/li&gt;
&lt;li&gt;Less sensitive to data order or noise.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;related-concept-kl-divergence&#34;&gt;Related Concept: KL Divergence&lt;/h3&gt;
&lt;p&gt;Another flavor of entropy is &lt;strong&gt;Kullback‚ÄìLeibler divergence (KL divergence)&lt;/strong&gt;. Think of it as a way to measure the &amp;ldquo;distance&amp;rdquo; between two probability worlds:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;One world is what &lt;em&gt;actually&lt;/em&gt; happens (distribution &lt;strong&gt;p&lt;/strong&gt;).&lt;/li&gt;
&lt;li&gt;The other is what your model &lt;em&gt;thinks&lt;/em&gt; will happen (distribution &lt;strong&gt;q&lt;/strong&gt;).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;KL divergence tells you how far off your model is‚Äîand how much it needs to learn. It‚Äôs like a map for loss, guiding your model back toward reality.&lt;/p&gt;
&lt;p&gt;GANs (Generative Adversarial Networks) use this idea to help the generator produce images that look increasingly real. The better it gets at mimicking the real distribution, the smaller the divergence.&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;alt text&#34; srcset=&#34;
               /post/machine-learning/entropy/KL_huf221c4c03880c66097e85ad3bf7df6f9_52023_fe99a68586fcefd1732d76fb2c078899.png 400w,
               /post/machine-learning/entropy/KL_huf221c4c03880c66097e85ad3bf7df6f9_52023_d0f636f329a3297908d6bc22f42ca50b.png 760w,
               /post/machine-learning/entropy/KL_huf221c4c03880c66097e85ad3bf7df6f9_52023_1200x1200_fit_lanczos_3.png 1200w&#34;
               src=&#34;https://leminhnguyen.github.io/post/machine-learning/entropy/KL_huf221c4c03880c66097e85ad3bf7df6f9_52023_fe99a68586fcefd1732d76fb2c078899.png&#34;
               width=&#34;700&#34;
               height=&#34;239&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h3 id=&#34;why-entropy-matters&#34;&gt;Why Entropy Matters&lt;/h3&gt;
&lt;p&gt;Unlike rigid metrics like accuracy, entropy-based measures capture the uncertainty and depth of the problem space. They allow models to:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Learn better under uncertainty.&lt;/li&gt;
&lt;li&gt;Make probabilistic predictions.&lt;/li&gt;
&lt;li&gt;Avoid problems like vanishing gradients (especially when used with softmax or sigmoid activations).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Whether you&amp;rsquo;re building a decision tree, training a neural network, or experimenting with probabilistic models, &lt;strong&gt;entropy is the invisible force guiding better decisions&lt;/strong&gt;.&lt;/p&gt;
&lt;h3 id=&#34;final-thoughts&#34;&gt;Final Thoughts&lt;/h3&gt;
&lt;p&gt;Entropy might seem abstract at first, but it captures a truth at the heart of machine learning: we are always trying to reduce uncertainty. By optimizing for entropy-based metrics like information gain, cross-entropy, or KL divergence, we empower our models to learn faster, perform better, and make smarter predictions.&lt;/p&gt;
&lt;p&gt;Entropy is not just a formula. It‚Äôs a mindset. A way of accepting that knowledge is never perfect, but it &lt;em&gt;can&lt;/em&gt; be improved. When we train models with entropy in mind, we embrace the chaos‚Äîand turn it into clarity.&lt;/p&gt;
&lt;h3 id=&#34;references&#34;&gt;References&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;üîó &lt;a href=&#34;https://medium.com/data-science/understanding-entropy-the-golden-measurement-of-machine-learning-4ea97c663dc3&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://medium.com/data-science/understanding-entropy-the-golden-measurement-of-machine-learning-4ea97c663dc3&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;üîó &lt;a href=&#34;https://huggingface.co/blog/hexgrad/g2p&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://huggingface.co/blog/hexgrad/g2p&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>
