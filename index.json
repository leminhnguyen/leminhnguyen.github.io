[{"authors":null,"categories":null,"content":"I\u0026rsquo;m leminhnguyen (nguyenlm)¬†üëã I'm a graduate student from HUST with Software Engineering degree and getting started studying Master of Data Science.¬†I‚Äôm currently working on End-To-End TTS models and Software Development techniques like AWS.¬†Falling in love with Data Science and Software Engineering.¬†Results from research must be applied in real life so I'm learning more and more to bridge research and development together. ","date":1656586285,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1656586285,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"I\u0026rsquo;m leminhnguyen (nguyenlm)¬†üëã I'm a graduate student from HUST with Software Engineering degree and getting started studying Master of Data Science.¬†I‚Äôm currently working on End-To-End TTS models and Software Development techniques like AWS.","tags":null,"title":"Le Minh Nguyen (nguyenlm)","type":"authors"},{"authors":["Le Minh Nguyen (nguyenlm)"],"categories":["NLP","TTS"],"content":"üí£ Batch vs Layer Normalization The purpose of normalization is to provide an uniform scale for the input data to avoid varing in huge range. The normalization method ensures there is no loss of information and even the range of values isn't affected. In spite of normalizing the input data, the value of activations of certain neurons in the hidden layers can start varying across a wide scale during the training process. This means the input to the neurons to the next hidden layer will also range across the wide range, bringing instability.\rBatch Normalization Layer is applied for neural networks where the training is done in mini-batches. We divide the data into batches with a certain batch size and then pass it through the network. Batch normalization is applied on the neuron activation for all the samples in the mini-batch such that the mean of output lies close to 0 and the standard deviation lies close to 1. It also introduces two learning parameters gama and beta in its calculation which are all optimized during training. 1\nLayer Normalization which addresses the drawbacks of batch normalization. This technique is not dependent on batches and the normalization is applied on the neuron for a single instance across all features. Here also mean activation remains close to 0 and mean standard deviation remains close to 1. 1\nThe key difference Batch Normalization depends on mini-batch size and may not work properly for smaller batch sizes. On the other hand, Layer normalization does not depend on mini-batch size. In batch normalization, input values of the same neuron for all the data in the mini-batch are normalized. Whereas in layer normalization, input values for all neurons in the same layer are normalized for each data sample. Batch normalization works better with fully connected layers and convolutional neural network (CNN) but it shows poor results with recurrent neural network (RNN). On the other hand, the main advantage of Layer normalization is that it works really well with RNN. Batch-vs-Layer-Normalization\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":1646823677,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1661427759,"objectID":"370544ef9d80f5d05bd39476e0d961c1","permalink":"https://leminhnguyen.github.io/post/tts-learns/tts-learns/","publishdate":"2022-03-09T11:01:17.461Z","relpermalink":"/post/tts-learns/tts-learns/","section":"post","summary":"The purpose of this post is just to understand the key difference between two types of well-known normalization techniques.","tags":["tts","learning"],"title":"Comparing batch vs layer normalization","type":"post"},{"authors":["Le Minh Nguyen (nguyenlm)"],"categories":["Linux","OS","Python"],"content":"Overview One day, I\u0026rsquo;ve tried to run a python script using multiprocessing technique n_jobs=10 and for a while the program crashed and raised the [Errno 32] Broken pipe error. With some google searches I founded the problem as well the solution for it.\n\u0026ldquo;Broken pipe\u0026rdquo; is essentially an IOError error (short for input/output error), which happened at the Linux system level. It usually occurs when reading and writing files, or in other words, doing file input/output or network input/output (via sockets) 1.\nIn programs that uses worker processes to speed up processing and make use of multi-core CPUs, you can try reducing the number of the worker processes to see whether the error disappear or not 1.\nFrom that suggestion, I reduced n_jobs=10 to n_jobs=5 and boom, the error got disappeared.\n[Errno 32] Broken pipe in Python\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":1646823677,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1656586878,"objectID":"38e8c5acfe7df1223121de21fc9bc302","permalink":"https://leminhnguyen.github.io/post/linux-learns/broken-pipe-error/","publishdate":"2022-03-09T11:01:17.461Z","relpermalink":"/post/linux-learns/broken-pipe-error/","section":"post","summary":"One day, I‚Äôve tried to run a python script using the multiprocessing technique and for a while the program crashed and raised the [Errno 32] Broken pipe error...","tags":["tts","learning"],"title":"Fix \"[Errno 32] Broken pipe\" in Python","type":"post"},{"authors":["Le Minh Nguyen (nguyenlm)"],"categories":["FirstBlood","Python"],"content":"Overview image created by me Get Started image created by me ","date":1646823677,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1654514213,"objectID":"279b9966ca9cf3121ce924dca452bb1c","permalink":"https://leminhnguyen.github.io/post/how-did-i-learn-python/","publishdate":"2022-03-09T11:01:17.461Z","relpermalink":"/post/how-did-i-learn-python/","section":"post","summary":"Hi all üëã ƒê√¢y l√† blog ƒë·∫ßu ti√™n c·ªßa m√¨nh, ·ªü trong blog n√†y m√¨nh s·∫Ω chia s·∫ª v·ªõi m·ªçi ng∆∞·ªùi v·ªÅ nh·ªØng kinh nghi·ªám trong t·ª± h·ªçc Python trong g·∫ßn 4 nƒÉm qua c·ªßa m√¨nh v√† c≈©ng nh∆∞ nh·ªØng ngu·ªìn t√†i li·ªáu m√† m√¨nh th∆∞·ªùng s·ª≠ d·ª•ng. Hi v·ªçng r·∫±ng blog n√†y s·∫Ω cung c·∫•p th√™m cho c√°c b·∫°n b·∫Øt ƒë·∫ßu h·ªçc Python m·ªôt ngu·ªìn tham kh·∫£o h·ªØu √≠ch üòÉ.","tags":["Python"],"title":"How did I learn Python ?","type":"post"},{"authors":["Le Minh Nguyen (nguyenlm)"],"categories":["Linux","OS"],"content":"Overview What is a zombie process? As you know, in Linux OS when we start an application the OS will create a process and this process can start other processes. The process starts other processes is refered as the parent and the new processes are refered as the children. The Linux OS keeps the information of processes in a table called the process table. The parent and the children run almost independently, but sometimes they share some resources (input, output) or contexts. When a child finished its job, it will send a SIGCHLD signal to the parent. The parent then reads the exit code of the child and removes its entry from the process table, this also cleans the resources used by the child. But there are sometimes the children cannot send the SIGCHLD signal to the parent or the parent was died by incident, in such cases the children outlive from their parent and the Linux OS refers them as orphaned or zombie processes.\nThe problem of zombie processes Because of outliving the parent, the resources used by the children (zombie) cannot be released, and hence, other processes cannot use these resources. To overcome this problem, we need to kill the children manually based on their ids. But, the main question is how we can find the the ids of the children? To answer that question, let\u0026rsquo;s continue to the next sections.\nKilling zombie processes using GPU Working as a research engineer, I\u0026rsquo;m usually using GPUs to train the deep learning models and checking the used resources with nvtop command. Usually each process using GPU will has an entry in the nvtop table and the Linux kernel refers that process as the parent process, the entry consists of some information about that process, for example, PID - the parent id, USER - the user that the parent belongs to, GPU - the GPU id used by the parent\u0026hellip; To kill a process using GPU we simply use the command kill PID or kill -9 PID, but there are some cases we cannot kill the process by that way, for example, the process has PID=18309 in the figure1. This because the process (parent) is already dead (indicated by N/A USER column) but the children (orphaned) are still alive and hold the resouces (in this case, the zombie proceses are holding about 85% GPU MEM). In order to access the child processes you have to excute sudo fuser -v /dev/nvidia* and all processes using GPUs will be listed with each GPU id. For example, when running the sudo fuser -v /dev/nvidia* command on my training server we will see the output looks like:\n$ sudo fuser -v /dev/nvidia*\rUSER PID ACCESS COMMAND\r/dev/nvidia0: nguyenlm 15909 F.... nvtop\rnguyenlm 20717 F.... nvtop\rnguyenlm 21042 F.... nvtop\rroot 24536 F.... nvtop\rnguyenlm 24787 F...m tensorboard\rnguyenlm 25078 F...m python\rnguyenlm 25079 F...m python\rnguyenlm 25080 F...m python\rnguyenlm 25081 F...m python\rnguyenlm 25082 F...m python\rnguyenlm 25085 F...m python\rnguyenlm 32199 F...m python\rFrom the output, we have a dozen of processes using GPU=0 (python, nvtop, tensorboard). Simply, we can kill them all with their PIDs by the kill command as mentioned to release the resources. However, we can do that easier by an observation, the zombie processes are usually have consecutive ids, so if we look the output carefully we will see a group of processes has the id ranged from 25078 to 25082 and those actually are zombie PIDs.\nReferences: Kill zombie process using GPU memory The subprocess Module: Wrapping Programs With Python ","date":1646823677,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1656586541,"objectID":"3e01837e6b4ce96f8b12fbae1f4afe93","permalink":"https://leminhnguyen.github.io/post/linux-learns/kill-zombie-processes/","publishdate":"2022-03-09T11:01:17.461Z","relpermalink":"/post/linux-learns/kill-zombie-processes/","section":"post","summary":"The trick for killing zombie processes using GPU in Linux üòÉ.","tags":["tts","learning"],"title":"How to kill zombie processes using GPU ?","type":"post"},{"authors":["Le Minh Nguyen (nguyenlm)"],"categories":["NLP","TTS"],"content":"Overview Comparing different methods\rThis section compares Phoneme Hallucinator kNN-VC and FreeVC.\nSource\rTarget\rkNN-VC\rPhoneme Hallucinator\r","date":1646823677,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1661426940,"objectID":"31e2bb3d8acb858950ec194320a0524f","permalink":"https://leminhnguyen.github.io/post/tts-learns/voice-conversion/","publishdate":"2022-03-09T11:01:17.461Z","relpermalink":"/post/tts-learns/voice-conversion/","section":"post","summary":"Overview Comparing different methods\rThis section compares Phoneme Hallucinator kNN-VC and FreeVC.\nSource\rTarget\rkNN-VC\rPhoneme Hallucinator\r","tags":["tts","learning"],"title":"KNN-VC vs Phoneme Hallucinator ?","type":"post"},{"authors":["Le Minh Nguyen (nguyenlm)"],"categories":["NLP","TTS"],"content":"üí£ Postnet Layer In some end-to-end TTS models today, after the hidden representations are passed through the decoder we got the mel-spectrogram which contains the predictions of the acoustic features. Finally, the decoder predictions are passed over the Postnet layer which predicts residual information to improve the construction performance of the model . The section below notes some insights about the Postnet layer by me when learning TTS.\r1. https://arxiv.org/pdf/1908.11535.pdf - 30 Aug 2019\rIn addition to the decoder, some systems have a post-net, an additional network that predicts acoustic features. A post-net was originally introduced to convert acoustic features to different acoustic features that were suitable for an adopted waveform synthesis method, for example, from mel spectrograms to linear spectrograms [2] or mel spectrograms to vocoder parameters [4]. In recent studies the role of the post-net was to improve the acoustic features predicted by the decoder to improve quality further [5, 6]. The post-net introduces an additional loss term in the objective function.\n2. https://arxiv.org/pdf/2008.03388.pdf - 11 Aug 2020\rRelative to DAR, C-DAR has three additional changes that do not significantly impact naturalness or controllability, but provide additional insights into F0 generation. First, a 5-layer postnet [3] follows the autoregressive RNN. We find that this postnet has the effect of reducing autoregressive sampling errors and tightening the posterior distribution around the argmax (Figure 2)\n","date":1646823677,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1661427689,"objectID":"3d9b59f3de00fa447c95a3510b140072","permalink":"https://leminhnguyen.github.io/post/tts-learns/postnet-layer/","publishdate":"2022-03-09T11:01:17.461Z","relpermalink":"/post/tts-learns/postnet-layer/","section":"post","summary":"Generally speaking, the postnet layer receives a mel-spectrogram and predicts another mel-spectrogram with additional information. That makes the output mel-spectrogram more detail, and hence improves the quality of synthesis audio.","tags":["tts","learning"],"title":"Postnet Layer","type":"post"},{"authors":["Le Minh Nguyen (nguyenlm)"],"categories":null,"content":"","date":1642500575,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1642500575,"objectID":"9413fdc7864cdaa721d77e5a988790ce","permalink":"https://leminhnguyen.github.io/publication/talk-unittesting-for-data-science/","publishdate":"2022-01-18T10:09:35.067Z","relpermalink":"/publication/talk-unittesting-for-data-science/","section":"publication","summary":"This talk give you some ideals about the purpose of unittest? how to write good unittest? how to use pytest framework? and show you the basic unittest structure for your project.","tags":null,"title":"Talk: Unittesting for Data Science","type":"publication"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"8576ec274c98b3831668a172fa632d80","permalink":"https://leminhnguyen.github.io/about/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/about/","section":"","summary":"","tags":null,"title":"","type":"widget_page"}]