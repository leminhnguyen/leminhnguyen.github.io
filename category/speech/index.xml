<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Speech | leminhnguyen&#39;s blog</title>
    <link>https://leminhnguyen.github.io/category/speech/</link>
      <atom:link href="https://leminhnguyen.github.io/category/speech/index.xml" rel="self" type="application/rss+xml" />
    <description>Speech</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><copyright>¬© {2025} leminhnguyen</copyright><lastBuildDate>Mon, 28 Apr 2025 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://leminhnguyen.github.io/media/icon_hua2ec155b4296a9c9791d015323e16eb5_11927_512x512_fill_lanczos_center_3.png</url>
      <title>Speech</title>
      <link>https://leminhnguyen.github.io/category/speech/</link>
    </image>
    
    <item>
      <title>Sortformer: A novel approach to speaker diarization</title>
      <link>https://leminhnguyen.github.io/post/speech-research/speaker-diarization/</link>
      <pubDate>Mon, 28 Apr 2025 00:00:00 +0000</pubDate>
      <guid>https://leminhnguyen.github.io/post/speech-research/speaker-diarization/</guid>
      <description>













&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /post/speech-research/speaker-diarization/sortformer-v1_hu1221356e5a41b9a0ee246c50935df5e7_373277_ae505eafbfe2f48d5ad0bd58f1a5160e.png 400w,
               /post/speech-research/speaker-diarization/sortformer-v1_hu1221356e5a41b9a0ee246c50935df5e7_373277_289e00f5fa3aa5664c30d2e843e20211.png 760w,
               /post/speech-research/speaker-diarization/sortformer-v1_hu1221356e5a41b9a0ee246c50935df5e7_373277_1200x1200_fit_lanczos_3.png 1200w&#34;
               src=&#34;https://leminhnguyen.github.io/post/speech-research/speaker-diarization/sortformer-v1_hu1221356e5a41b9a0ee246c50935df5e7_373277_ae505eafbfe2f48d5ad0bd58f1a5160e.png&#34;
               width=&#34;479&#34;
               height=&#34;760&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;div style=&#34;text-align: justify; font-size: 15px;&#34;&gt;
&lt;h3 id=&#34;traditional-method&#34;&gt;Traditional Method&lt;/h3&gt;
&lt;p&gt;Diarization, in the context of audio processing and speech recognition, is the process of partitioning an audio stream into segments according to the identity of the speaker. The main goal of diarization is to determine &lt;code&gt; who spoke when &lt;/code&gt; in an audio recording that includes multiple speakers. This process is essential in applications where distinguishing between different speakers is crucial, such as in meeting transcription, broadcast news analysis, and call center monitoring.&lt;/p&gt;














&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /post/speech-research/speaker-diarization/traditional_diar_hua7f002cd508fa95ba83464a48feb282c_171994_9bd4912a2e36e703ab217f84e7f104a5.png 400w,
               /post/speech-research/speaker-diarization/traditional_diar_hua7f002cd508fa95ba83464a48feb282c_171994_59370a29b144f19cf032b93530b94476.png 760w,
               /post/speech-research/speaker-diarization/traditional_diar_hua7f002cd508fa95ba83464a48feb282c_171994_1200x1200_fit_lanczos_3.png 1200w&#34;
               src=&#34;https://leminhnguyen.github.io/post/speech-research/speaker-diarization/traditional_diar_hua7f002cd508fa95ba83464a48feb282c_171994_9bd4912a2e36e703ab217f84e7f104a5.png&#34;
               width=&#34;760&#34;
               height=&#34;343&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;p&gt;&lt;strong&gt;Traditional Method&lt;/strong&gt;
Those consist of many independent submodules that are optimized individually, namely being:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Speech detection:&lt;/strong&gt;¬†The first step is to identify speech and remove non-speech signals with a voice activity detector (VAD) algorithm.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Speech segmentation:&lt;/strong&gt;¬†The output of the VAD is then segmented into small segments consisting of a few seconds.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Speech embedder:&lt;/strong&gt;¬†A neural network pre-trained on speaker recognition is used to derive a high-level representation of the speech segments. Those embeddings are vector representations that summarize the voice characteristics (a.k.a voice print).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Clustering:&lt;/strong&gt;¬†After extracting segment embeddings, we need to cluster the speech embeddings with a clustering algorithm (for example K-Means or spectral clustering). The clustering produces our desired diarization results, which consists of identifying the number of unique speakers (derived from the number of unique clusters) and assigning a speaker label to each embedding (or speech segment).&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;end-to-end-method&#34;&gt;End To End Method&lt;/h3&gt;
&lt;p&gt;In multi-speaker speech processing tasks like speaker diarization, correctly identifying &amp;ldquo;who spoke when&amp;rdquo; is a long-standing challenge. Traditional systems use separate pipelines for speech recognition and diarization. More recent models like Sortformer aim to unify these tasks, with a focus on improving performance and training efficiency.&lt;/p&gt;
&lt;div style=&#34;text-align: justify; font-size: 15px; margin-top: -15px; margin-bottom: 10px&#34;&gt;
A core innovation in Sortformer is the use of &lt;code&gt; Sort Loss&lt;/code&gt; ‚Äî a loss function that leverages the order in which speakers begin talking. Combined with Binary Cross-Entropy (BCE) instead of traditional Cross Entropy (CE), this framework is optimized for overlapping speakers and multi-label classification.
&lt;/div&gt;
&lt;div style=&#34;text-align: justify; font-size: 15px;&#34;&gt;
In this blog post, we&#39;ll explain:
&lt;ul style=&#34;margin-top: 0px; margin-bottom: 0; padding-left: 30px;&#34;&gt;
&lt;li style=&#34;margin-bottom: 0px;&#34;&gt;How Sort Loss works.&lt;/li&gt;
&lt;li style=&#34;margin-bottom: 0px;&#34;&gt;How Sortformer training happens.&lt;/li&gt;
&lt;li style=&#34;margin-bottom: 0px;&#34;&gt;Why we use Binary Cross-Entropy (BCE) instead of traditional Cross-Entropy (CE).&lt;/li&gt;
&lt;li style=&#34;margin-bottom: 0px;&#34;&gt;How Softmax and Sigmoid activations differ.&lt;/li&gt;
&lt;li style=&#34;margin-bottom: 0px;&#34;&gt;Tiny examples to make it crystal clear!&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;h3 id=&#34;what-problem-does-sort-loss-solve&#34;&gt;What Problem Does Sort Loss Solve?&lt;/h3&gt;
&lt;p&gt;Speaker diarization models predict &lt;strong&gt;who&lt;/strong&gt; is speaking at &lt;strong&gt;each frame&lt;/strong&gt; of audio. But ‚Äî &lt;strong&gt;the model doesn&amp;rsquo;t know speaker identities&lt;/strong&gt;! It only uses generic speaker labels (e.g., Speaker-0, Speaker-1). Traditional training needs to match predicted speakers to ground-truth speakers, trying every possible permutation (PIL) ‚Äî very expensive when many speakers exist!&lt;/p&gt;
&lt;div style=&#34;text-align: justify; font-size: 15px; margin-top: -15px;&#34; markdown=&#34;1&#34;&gt;
&lt;p&gt;&lt;strong&gt;Sortformer&lt;/strong&gt; solves this by introducing &lt;strong&gt;Sort Loss&lt;/strong&gt;:&lt;/p&gt;
&lt;ul style=&#34;margin-top: -15px; margin-bottom: 0; padding-left: 30px;&#34;&gt;
&lt;li style=&#34;margin-bottom: 0px;&#34; markdown=&#34;1&#34;&gt;Sort speakers &lt;code&gt; by their speaking start time &lt;/code&gt; (Arrival Time Order ‚Äî ATO)&lt;/li&gt;
&lt;li style=&#34;margin-bottom: 0px;&#34;&gt;Always treat the first speaker as Speaker-0, second as Speaker-1, etc&lt;/li&gt;
&lt;li style=&#34;margin-bottom: 0px;&#34;&gt;No need for heavy permutation matching!&lt;/li&gt;
&lt;/div&gt;
&lt;h3 id=&#34;-what-is-the-permutation-problem-in-speaker-diarization&#34;&gt;üåü What Is the Permutation Problem in Speaker Diarization?&lt;/h3&gt;
&lt;p&gt;Speaker diarization systems assign speaker labels to segments of audio. But unlike speaker identification, the identities are generic &lt;code&gt; Speaker-0 &lt;/code&gt;, &lt;code&gt; Speaker-1 &lt;/code&gt;, etc. That creates a permutation problem: the system might label Speaker-A as Speaker-0 in one instance and Speaker-1 in another. Traditionally, this is handled using Permutation Invariant Loss (PIL) or Permutation Invariant Training (PIT):&lt;/p&gt;
&lt;ul style=&#34;margin-top: -15px; margin-bottom: 10px; padding-left: 30px;&#34;&gt;
&lt;li&gt;PIL checks all possible mappings of predicted labels to ground-truth and picks the one with the lowest loss.
&lt;/li&gt;
&lt;li&gt;It becomes expensive as the number of speakers increases: time complexity is &lt;code&gt;O(N!)&lt;/code&gt; or at best &lt;code&gt;O(N¬≥)&lt;/code&gt; using the Hungarian algorithm.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;That‚Äôs where Sortformer introduces a breakthrough idea. Why not just sort speakers by who spoke first and train the model to always follow this order? This is the foundation of Sort Loss.&lt;/p&gt;
&lt;h3 id=&#34;how-sortformer-training-works&#34;&gt;How Sortformer Training Works&lt;/h3&gt;
&lt;p&gt;The training steps are:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Input audio&lt;/strong&gt; ‚ûî Extract frame-wise features.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Sort the ground-truth speakers&lt;/strong&gt; by their &lt;strong&gt;start time&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Model predicts&lt;/strong&gt; frame-level speaker activities independently (using Sigmoid).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Calculate Sort Loss&lt;/strong&gt;: Match model outputs with sorted true labels using &lt;strong&gt;Binary Cross-Entropy&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Backpropagate&lt;/strong&gt; and update model.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;‚úÖ Speakers who speak earlier are consistently mapped to earlier speaker labels during training!&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;-sort-loss-formula&#34;&gt;üìú Sort Loss Formula&lt;/h3&gt;
&lt;p&gt;The Sort Loss formula is:
$$L_{\text{Sort}}(Y, P) = \frac{1}{K} \sum_{k=1}^{K} \text{BCE}(y_{\eta(k)}, q_k)$$
where:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$Y$ = ground-truth speaker activities.&lt;/li&gt;
&lt;li&gt;$P$ = predicted speaker probabilities.&lt;/li&gt;
&lt;li&gt;$\eta(k)$ = the sorted index by arrival time.&lt;/li&gt;
&lt;li&gt;$K$ = number of speakers.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;BCE&lt;/strong&gt; = Binary Cross-Entropy loss for each speaker&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;‚úÖ Each speaker is evaluated independently.&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;-why-binary-cross-entropy-bce-not-normal-cross-entropy&#34;&gt;ü§î Why Binary Cross-Entropy (BCE), Not Normal Cross-Entropy?&lt;/h3&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left&#34;&gt;Feature&lt;/th&gt;
&lt;th style=&#34;text-align:left&#34;&gt;Cross Entropy (CE)&lt;/th&gt;
&lt;th style=&#34;text-align:left&#34;&gt;Binary Cross Entropy (BCE)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Use case&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Single-label classification&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Multi-label classification&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Output Activation&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Softmax (probabilities sum to 1)&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Sigmoid (independent probabilities)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Can handle overlaps?&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;‚ùå No&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;‚úÖ Yes&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Example&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Pick one animal (cat, dog, rabbit)&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Pick all fruits you like (apple, banana, grape)&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;In speaker diarization:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Multiple speakers can talk at once&lt;/strong&gt; ‚ûî multi-label ‚ûî &lt;strong&gt;Binary Cross Entropy is needed&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;Each speaker is predicted &lt;strong&gt;independently&lt;/strong&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id=&#34;-tiny-example-of-sort-loss-in-action&#34;&gt;üî• Tiny Example of Sort Loss in Action&lt;/h3&gt;
&lt;p&gt;Suppose we have 2 speakers and 3 frames:&lt;/p&gt;
&lt;p&gt;Ground-truth (after sorting):&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;Frame&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;spk0&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;spk1&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;t1&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;1&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;t2&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;1&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;t3&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;0&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Predicted outputs:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;Frame&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;spk0&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;spk1&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;t1&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;0.9&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;0.1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;t2&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;0.6&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;0.8&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;t3&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;0.2&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;0.7&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Binary Cross Entropy is applied &lt;strong&gt;separately for each speaker&lt;/strong&gt;, and averaged over speakers.&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;-quick-summary-softmax-vs-sigmoid&#34;&gt;üß† Quick Summary: Softmax vs Sigmoid&lt;/h3&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left&#34;&gt;&lt;/th&gt;
&lt;th style=&#34;text-align:left&#34;&gt;Softmax&lt;/th&gt;
&lt;th style=&#34;text-align:left&#34;&gt;Sigmoid&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Sum of outputs&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;1&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Not necessarily&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Mutual exclusivity&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Yes&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Application&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Single-label classification (only 1 class active)&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Multi-label classification (multiple active)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Used with&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Cross Entropy Loss&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Binary Cross Entropy Loss&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;‚úÖ &lt;strong&gt;Softmax&lt;/strong&gt; is used with Cross Entropy.&lt;br&gt;
‚úÖ &lt;strong&gt;Sigmoid&lt;/strong&gt; is used with Binary Cross Entropy.&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;-conclusion&#34;&gt;üì¶ Conclusion&lt;/h3&gt;
&lt;p&gt;‚úÖ Sortformer introduces a faster, more elegant solution for speaker diarization by sorting speakers by arrival time and applying simple Binary Cross-Entropy.&lt;/p&gt;
&lt;p&gt;‚úÖ BCE and Sigmoid are natural choices when multiple speakers can overlap.&lt;/p&gt;
&lt;p&gt;‚úÖ No more expensive permutation matching is needed!&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;-final-words&#34;&gt;üèÅ Final Words&lt;/h3&gt;
&lt;p&gt;This approach is simpler, faster, and works better for multi-speaker real-world conversations.
Stay tuned for more tutorials where we dive into multispeaker ASR models and joint training with speaker supervision!&lt;/p&gt;
&lt;/div&gt;</description>
    </item>
    
  </channel>
</rss>
